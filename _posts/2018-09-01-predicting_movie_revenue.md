---
layout: default
title:  "Predicting revenue generated by movies"
permalink: "/predict_movie_revenue/"
---

# <center>Predicting revenue generated by movies</center>
## <center>Python</center>

In my last post, I tried my hand at predicting movie ratings. I'll use the same dataset with the dummy variables and replace the response variable, previously *ratings*, with *revenue*.

Since all the data cleaning is done, I can move straight into the exploratory data analysis.

## Set up and import data


```python
import pandas as pd
import numpy as np

from matplotlib import pyplot as plt
import seaborn as sns

from sklearn import linear_model as lm, metrics, tree, ensemble, model_selection as ms

%matplotlib inline

pd.options.mode.chained_assignment = None

np.random.seed(42)
```


```python
sns.set(rc={
    'figure.figsize': (12, 8),
    'font.size': 14
})

# Set palette
sns.set_palette("husl")
```


```python
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_rows', 5000)
```


```python
movies = pd.read_csv("/Users/jasminepengelly/Desktop/projects/predicting_movie/movies_wo_dir.csv")
movies.drop("Unnamed: 0", axis=1, inplace=True)
```


```python
movies.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>id</th>
      <th>budget</th>
      <th>revenue</th>
      <th>runtime</th>
      <th>vote_average</th>
      <th>vote_count</th>
      <th>belongs_to_collection</th>
      <th>Action</th>
      <th>Adventure</th>
      <th>Animation</th>
      <th>Aniplex</th>
      <th>BROSTA TV</th>
      <th>Carousel Productions</th>
      <th>Comedy</th>
      <th>Crime</th>
      <th>Documentary</th>
      <th>Drama</th>
      <th>Family</th>
      <th>Fantasy</th>
      <th>Foreign</th>
      <th>GoHands</th>
      <th>History</th>
      <th>Horror</th>
      <th>Mardock Scramble Production Committee</th>
      <th>Music</th>
      <th>Mystery</th>
      <th>Odyssey Media</th>
      <th>Pulser Productions</th>
      <th>Rogue State</th>
      <th>Romance</th>
      <th>Science Fiction</th>
      <th>Sentai Filmworks</th>
      <th>TV Movie</th>
      <th>Telescene Film Group Productions</th>
      <th>The Cartel</th>
      <th>Thriller</th>
      <th>Vision View Entertainment</th>
      <th>War</th>
      <th>Western</th>
      <th>lead</th>
      <th>supporting</th>
      <th>dir_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Toy Story</td>
      <td>862</td>
      <td>30000000.0</td>
      <td>373554033.0</td>
      <td>81.0</td>
      <td>7.7</td>
      <td>5415.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Tom Hanks</td>
      <td>Tim Allen</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jumanji</td>
      <td>8844</td>
      <td>65000000.0</td>
      <td>262797249.0</td>
      <td>104.0</td>
      <td>6.9</td>
      <td>2413.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Robin Williams</td>
      <td>Jonathan Hyde</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heat</td>
      <td>949</td>
      <td>60000000.0</td>
      <td>187436818.0</td>
      <td>170.0</td>
      <td>7.7</td>
      <td>1886.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Al Pacino</td>
      <td>Robert De Niro</td>
      <td>10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sudden Death</td>
      <td>9091</td>
      <td>35000000.0</td>
      <td>64350171.0</td>
      <td>106.0</td>
      <td>5.5</td>
      <td>174.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Jean-Claude Van Damme</td>
      <td>Powers Boothe</td>
      <td>10</td>
    </tr>
    <tr>
      <th>4</th>
      <td>GoldenEye</td>
      <td>710</td>
      <td>58000000.0</td>
      <td>352194034.0</td>
      <td>130.0</td>
      <td>6.6</td>
      <td>1194.0</td>
      <td>1</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Pierce Brosnan</td>
      <td>Sean Bean</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div>



## Exploratory data analysis

From my previous analysis, I know there was a relationship between *budget*, *revenue* and *vote_count*. This time around I'll focus on the relationships between *ratings* and the other variables.

First, I'll define the variables that I'm using.


```python
X = ['budget', 'runtime', 'vote_count', 'belongs_to_collection', 'Action', 'Adventure',
              'Animation', 'Aniplex', 'BROSTA TV', 'Carousel Productions', 'Comedy', 'Crime', 'Documentary', 'Drama',
              'Family', 'Fantasy', 'Foreign', 'GoHands', 'History', 'Horror', 'Mardock Scramble Production Committee',
              'Music', 'Mystery', 'Odyssey Media', 'Pulser Productions', 'Rogue State', 'Romance', 'Science Fiction',
              'Sentai Filmworks', 'TV Movie', 'Telescene Film Group Productions', 'The Cartel', 'Thriller',
              'Vision View Entertainment', 'War', 'Western', 'lead', 'supporting', 'vote_average']

y = 'revenue'
```


```python
sns.heatmap(movies[X].corr(), vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(10, 220, sep=80, n=7))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x10a9edeb8>




![Correlation](https://raw.githubusercontent.com/JazPeng/assets/master/movies/rev_corr.png)


I already identified the correlation between *Family* and *Animation*, and *vote_count* and *budget*, are not significant enough to worry about. There is no need for PCA here.

### Highest revenue films


```python
high_rev = movies[['title', 'revenue']].sort_values(by = 'revenue', ascending = False).head(10)
high_rev['revenue'] = high_rev['revenue'].map('${:,.2f}'.format)
high_rev
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1439</th>
      <td>Avatar</td>
      <td>$2,787,965,087.00</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>Star Wars: The Force Awakens</td>
      <td>$2,068,223,624.00</td>
    </tr>
    <tr>
      <th>328</th>
      <td>Titanic</td>
      <td>$1,845,034,188.00</td>
    </tr>
    <tr>
      <th>1778</th>
      <td>Furious 7</td>
      <td>$1,506,249,360.00</td>
    </tr>
    <tr>
      <th>1540</th>
      <td>Harry Potter and the Deathly Hallows: Part 2</td>
      <td>$1,342,000,000.00</td>
    </tr>
    <tr>
      <th>1875</th>
      <td>Beauty and the Beast</td>
      <td>$1,262,886,337.00</td>
    </tr>
    <tr>
      <th>1881</th>
      <td>The Fate of the Furious</td>
      <td>$1,238,764,765.00</td>
    </tr>
    <tr>
      <th>1535</th>
      <td>Transformers: Dark of the Moon</td>
      <td>$1,123,746,996.00</td>
    </tr>
    <tr>
      <th>994</th>
      <td>The Lord of the Rings: The Return of the King</td>
      <td>$1,118,888,979.00</td>
    </tr>
    <tr>
      <th>1614</th>
      <td>Skyfall</td>
      <td>$1,108,561,013.00</td>
    </tr>
  </tbody>
</table>
</div>



### Highest grossing films


```python
movies["gross_profit"] = movies["revenue"] - movies["budget"]
high_gp = movies[['title', "gross_profit"]].sort_values(by = "gross_profit", ascending = False).head(10)
high_gp["gross_profit"] = high_gp["gross_profit"].map('${:,.2f}'.format)
high_gp
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>gross_profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1439</th>
      <td>Avatar</td>
      <td>$2,550,965,087.00</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>Star Wars: The Force Awakens</td>
      <td>$1,823,223,624.00</td>
    </tr>
    <tr>
      <th>328</th>
      <td>Titanic</td>
      <td>$1,645,034,188.00</td>
    </tr>
    <tr>
      <th>1778</th>
      <td>Furious 7</td>
      <td>$1,316,249,360.00</td>
    </tr>
    <tr>
      <th>1540</th>
      <td>Harry Potter and the Deathly Hallows: Part 2</td>
      <td>$1,217,000,000.00</td>
    </tr>
    <tr>
      <th>1875</th>
      <td>Beauty and the Beast</td>
      <td>$1,102,886,337.00</td>
    </tr>
    <tr>
      <th>994</th>
      <td>The Lord of the Rings: The Return of the King</td>
      <td>$1,024,888,979.00</td>
    </tr>
    <tr>
      <th>1881</th>
      <td>The Fate of the Furious</td>
      <td>$988,764,765.00</td>
    </tr>
    <tr>
      <th>1535</th>
      <td>Transformers: Dark of the Moon</td>
      <td>$928,746,996.00</td>
    </tr>
    <tr>
      <th>1614</th>
      <td>Skyfall</td>
      <td>$908,561,013.00</td>
    </tr>
  </tbody>
</table>
</div>



### Lowest revenue films


```python
low_rev = movies[['title', 'revenue']].sort_values(by = 'revenue', ascending = True).head(10)
low_rev['revenue'] = low_rev['revenue'].map('${:,.2f}'.format)
low_rev
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>576</th>
      <td>Angela's Ashes</td>
      <td>$13.00</td>
    </tr>
    <tr>
      <th>1271</th>
      <td>Death at a Funeral</td>
      <td>$46.00</td>
    </tr>
    <tr>
      <th>628</th>
      <td>The Idiots</td>
      <td>$7,235.00</td>
    </tr>
    <tr>
      <th>1604</th>
      <td>5 Days of War</td>
      <td>$17,479.00</td>
    </tr>
    <tr>
      <th>590</th>
      <td>City Lights</td>
      <td>$19,181.00</td>
    </tr>
    <tr>
      <th>1464</th>
      <td>Valhalla Rising</td>
      <td>$30,638.00</td>
    </tr>
    <tr>
      <th>480</th>
      <td>Following</td>
      <td>$48,482.00</td>
    </tr>
    <tr>
      <th>1678</th>
      <td>The Canyons</td>
      <td>$56,825.00</td>
    </tr>
    <tr>
      <th>1628</th>
      <td>Byzantium</td>
      <td>$89,237.00</td>
    </tr>
    <tr>
      <th>1796</th>
      <td>Manglehorn</td>
      <td>$143,101.00</td>
    </tr>
  </tbody>
</table>
</div>



### Biggest loss


```python
high_gp = movies[['title', "gross_profit"]].sort_values(by = "gross_profit", ascending = True).head(10)
high_gp["gross_profit"] = high_gp["gross_profit"].map('${:,.2f}'.format)
high_gp
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>gross_profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1673</th>
      <td>The Lone Ranger</td>
      <td>$-165,710,090.00</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>The Alamo</td>
      <td>$-119,180,039.00</td>
    </tr>
    <tr>
      <th>1884</th>
      <td>Valerian and the City of a Thousand Planets</td>
      <td>$-107,447,384.00</td>
    </tr>
    <tr>
      <th>513</th>
      <td>The 13th Warrior</td>
      <td>$-98,301,101.00</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Cutthroat Island</td>
      <td>$-87,982,678.00</td>
    </tr>
    <tr>
      <th>1365</th>
      <td>Australia</td>
      <td>$-80,445,998.00</td>
    </tr>
    <tr>
      <th>578</th>
      <td>Supernova</td>
      <td>$-75,171,919.00</td>
    </tr>
    <tr>
      <th>1080</th>
      <td>A Sound of Thunder</td>
      <td>$-74,010,360.00</td>
    </tr>
    <tr>
      <th>1128</th>
      <td>The Great Raid</td>
      <td>$-69,833,498.00</td>
    </tr>
    <tr>
      <th>1674</th>
      <td>R.I.P.D.</td>
      <td>$-68,351,500.00</td>
    </tr>
  </tbody>
</table>
</div>



## Modelling


```python
directors = pd.read_csv("/Users/jasminepengelly/Desktop/projects/predicting_movie/director_dummies.csv")
directors.drop("Unnamed: 0", axis=1, inplace=True)
```


```python
final = pd.merge(directors, movies, left_on = 'index', right_on = 'id')
final.drop(["id", "index", "title", "dir_count"], axis=1, inplace=True)
```

### Get dummy variables


```python
dummies = pd.get_dummies(final, columns=['lead', 'supporting'], drop_first=True)
```


```python
X = dummies.drop("revenue", axis=1)
y = dummies["revenue"]
```


```python
from sklearn.model_selection import train_test_split, KFold, cross_val_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(len(X_train), len(X_test))
print(len(y_train), len(y_test))
```

    1320 567
    1320 567


### Dumb model
First, I'll create a dumb model to compare the results of all my linear regression models with. This dumb model will try and predict the mean value and the RMSE will be the basis by which to judge the performance of my models.


```python
y_pred_mean = [y_train.mean()] * len(y_test)

print("Dumb model RMSE: ",'${:,.2f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred_mean))))
```

    Dumb model RMSE:  $257,481,879.43


$257,481,879.43 will be the benchmark RMSE for my model's success. It's still a very wide margin to be out by, so I'm hoping I can meet this.

### Linear regression
I will begin with a standard linear regression model and gradually make it more complex with cross-validation and regularisation. I will compare the accuracy of all the models and select the best version before I move onto other regression models.


```python
def get_linear_model_metrics(X_train, y_train, X_test, y_test, model):
    model.fit(X_train, y_train)
    residuals = (y_train - model.predict(X_train)).values
    print('Coefficients:', model.coef_)
    print('y-intercept:', model.intercept_)
    print('R-Squared:', model.score(X_train, y_train))
    print("Training error (RMSE): ",'${:,.2f}'.format(np.sqrt(metrics.mean_squared_error(y_train, residuals))))
    print("Testing error (RMSE): ",'${:,.2f}'.format(np.sqrt(metrics.mean_squared_error(y_test, lm.predict(X_test)))))

    plt.figure()
    plt.hist(residuals)
    return model
```

#### Standard linear regression model


```python
from sklearn import feature_selection, linear_model
```


```python
lm = linear_model.LinearRegression()

get_linear_model_metrics(X_train, y_train, X_test, y_test, lm)
```

    Coefficients: [ -7.31715178e+11  -5.80352121e+08  -4.55439589e+09 ...,  -2.55609859e+08
       0.00000000e+00   0.00000000e+00]
    y-intercept: 2774147964.66
    R-Squared: 0.99813577832
    Training error (RMSE):  $233,564,358.72
    Testing error (RMSE):  $12,070,332,112.59





    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)




![Residuals](https://raw.githubusercontent.com/JazPeng/assets/master/movies/rev_lr.png)


Though my R-Squared is high, this is not always a good indicator of a model. My training error is lower than my dumb model RMSE but my testing error is huge. This level of overfitting is to be expected when there is no cross-validation. My residuals are also not normally distributed.

#### Cross-validated linear regression model


```python
for k in range(5, 11):
    cv_scores = cross_val_score(linear_model.LinearRegression(), X_train, y_train, scoring='neg_mean_squared_error', cv=k)
    print("Scores for k =",k,":",list(map(lambda score: '${:,.2f}'.format(np.sqrt(-score)), cv_scores)))
    print("Variance: ", np.var(cv_scores))
    print("Mean RMSE for k =",k,":",'${:,.2f}'.format(np.mean(np.sqrt(-cv_scores))))
    print("\n")
```

    Scores for k = 5 : ['$95,622,531,768.83', '$76,850,749,502.14', '$115,452,433,317.23', '$26,234,975,584.43', '$991,718,832,743.41']
    Variance:  1.52504029555e+47
    Mean RMSE for k = 5 : $261,175,904,583.21


    Scores for k = 6 : ['$33,570,326,811.69', '$317,710,688.73', '$532,400,192,063.14', '$87,873,792,012.08', '$20,448,216,371.08', '$201,830,750,417.60']
    Variance:  1.05887620356e+46
    Mean RMSE for k = 6 : $146,073,498,060.72


    Scores for k = 7 : ['$282,298,574,974.10', '$838,391,949,948.27', '$1,423,956,517,961.58', '$116,922,922,049.26', '$48,661,521,035.89', '$264,902,200,318.47', '$23,774,404,590.15']
    Variance:  4.88278284855e+47
    Mean RMSE for k = 7 : $428,415,441,553.96


    Scores for k = 8 : ['$162,331,891,937.45', '$2,499,383,904,716.25', '$604,038,384,081.57', '$42,602,200,536.73', '$42,129,795,004.84', '$64,817,938,616.53', '$87,549,359,999.98', '$6,485,688,135.77']
    Variance:  4.20300719534e+48
    Mean RMSE for k = 8 : $438,667,395,378.64


    Scores for k = 9 : ['$33,306,735,139.99', '$13,004,306,954.76', '$71,254,703,096.25', '$6,341,599,453.29', '$33,361,038,342.75', '$6,995,975,143.81', '$30,612,901,289.40', '$84,665,545,481.97', '$116,257,633,741.55']
    Variance:  1.8735372837e+43
    Mean RMSE for k = 9 : $43,977,826,515.97


    Scores for k = 10 : ['$58,239,020,827.48', '$117,784,510,825.46', '$71,313,407,529.10', '$33,736,542,136.67', '$368,842,272,142.85', '$105,230,277,341.44', '$85,081,644,731.65', '$4,211,832,087.28', '$72,502,582,846.20', '$106,388,963,209.87']
    Variance:  1.52893948435e+45
    Mean RMSE for k = 10 : $102,333,105,367.80




The best performing *k* was 9, although the RMSE is much lower than that of my dumb model.

#### Regularisation with cross-validation


```python
from sklearn.linear_model import Lasso, Ridge
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings("ignore")
```

##### Ridge


```python
grid_ridge = GridSearchCV(estimator=Ridge(),
                    param_grid={'alpha': np.logspace(-10, 10, 21)},
                    scoring='neg_mean_squared_error',
                    return_train_score=True,
                    cv=9)

grid_ridge.fit(X_train, y_train)
```




    GridSearchCV(cv=9, error_score='raise',
           estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
       normalize=False, random_state=None, solver='auto', tol=0.001),
           fit_params=None, iid=True, n_jobs=1,
           param_grid={'alpha': array([  1.00000e-10,   1.00000e-09,   1.00000e-08,   1.00000e-07,
             1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,
             1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,
             1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,
             1.00000e+06,   1.00000e+07,   1.00000e+08,   1.00000e+09,
             1.00000e+10])},
           pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
           scoring='neg_mean_squared_error', verbose=0)




```python
print(np.sqrt(-grid_ridge.best_score_), grid_ridge.best_params_)
```

    101269662.594 {'alpha': 1000.0}



```python
best_model_ridge = grid_ridge.best_estimator_
print("grid_ridge training RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_train, best_model_ridge.predict(X_train)))))
print("grid_ridge testing RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_test, best_model_ridge.predict(X_test)))))
```

    grid_ridge training RMSE: $100,095,257.12
    grid_ridge testing RMSE: $149,154,130.53


While there still seems to be a considerable amount of overfitting judging on the differences between the training and the testing error, both are lower than the dumb model RSME. This is the best performing model so far. I'll see if Lasso produces better results.

##### Lasso


```python
grid_lasso = GridSearchCV(estimator=Lasso(),
                    param_grid={'alpha': np.logspace(-10, 10, 21)},
                    scoring='neg_mean_squared_error',
                    return_train_score=True,
                    cv=9)

grid_lasso.fit(X_train, y_train)
```




    GridSearchCV(cv=9, error_score='raise',
           estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
       normalize=False, positive=False, precompute=False, random_state=None,
       selection='cyclic', tol=0.0001, warm_start=False),
           fit_params=None, iid=True, n_jobs=1,
           param_grid={'alpha': array([  1.00000e-10,   1.00000e-09,   1.00000e-08,   1.00000e-07,
             1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,
             1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,
             1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,
             1.00000e+06,   1.00000e+07,   1.00000e+08,   1.00000e+09,
             1.00000e+10])},
           pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
           scoring='neg_mean_squared_error', verbose=0)




```python
print(np.sqrt(-grid_lasso.best_score_), grid_lasso.best_params_)
```

    94726187.3663 {'alpha': 100000.0}



```python
best_model_lasso = grid_lasso.best_estimator_
print("grid_lasso training RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_train, best_model_lasso.predict(X_train)))))
print("grid_lasso testing RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_test, best_model_lasso.predict(X_test)))))
```

    grid_lasso training RMSE: $61,080,253.95
    grid_lasso testing RMSE: $143,707,045.90


### Decision tree
To find the best parameters for *min_samples_leaf* and *max_depth*, I will use GridSearch along with a 9-fold cross-validation.


```python
from sklearn.tree import DecisionTreeRegressor
```


```python
min_samples_leaf = list(range(1, 11))
max_depth_range = list(range(1, 11))

grid_dt = GridSearchCV(estimator=DecisionTreeRegressor(),
                    param_grid={"min_samples_leaf": min_samples_leaf,
                                "max_depth": max_depth_range},
                    scoring="neg_mean_squared_error",
                    cv=9)

grid_dt.fit(X_train, y_train)
```




    GridSearchCV(cv=9, error_score='raise',
           estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,
               max_leaf_nodes=None, min_impurity_decrease=0.0,
               min_impurity_split=None, min_samples_leaf=1,
               min_samples_split=2, min_weight_fraction_leaf=0.0,
               presort=False, random_state=None, splitter='best'),
           fit_params=None, iid=True, n_jobs=1,
           param_grid={'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},
           pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
           scoring='neg_mean_squared_error', verbose=0)




```python
print(np.sqrt(-grid_dt.best_score_), grid_dt.best_params_)
```

    105122283.466 {'max_depth': 5, 'min_samples_leaf': 9}



```python
best_model_dt = grid_dt.best_estimator_
print("grid_dt training RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_train, best_model_dt.predict(X_train)))))
print("grid_dt testing RMSE: "'${:,.2f}'.format(np.sqrt(mean_squared_error(y_test, best_model_dt.predict(X_test)))))
```

    grid_dt training RMSE: $86,829,399.26
    grid_dt testing RMSE: $157,577,345.90


The *best_model_dt* has a marginly better training and testing error, although still looks like it might be overfitting. This is the best performing model so far. Now to look at the most effective features.


```python
pd.DataFrame({'feature':X_train.columns, 'coefficients':best_model_dt.feature_importances_}).sort_values(by='coefficients', axis=0, ascending=False).head(10)
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coefficients</th>
      <th>feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>247</th>
      <td>0.599197</td>
      <td>budget</td>
    </tr>
    <tr>
      <th>250</th>
      <td>0.346582</td>
      <td>vote_count</td>
    </tr>
    <tr>
      <th>249</th>
      <td>0.020226</td>
      <td>vote_average</td>
    </tr>
    <tr>
      <th>248</th>
      <td>0.019391</td>
      <td>runtime</td>
    </tr>
    <tr>
      <th>251</th>
      <td>0.014604</td>
      <td>belongs_to_collection</td>
    </tr>
    <tr>
      <th>1388</th>
      <td>0.000000</td>
      <td>supporting_Holly Hunter</td>
    </tr>
    <tr>
      <th>1390</th>
      <td>0.000000</td>
      <td>supporting_Hu Jun</td>
    </tr>
    <tr>
      <th>1391</th>
      <td>0.000000</td>
      <td>supporting_Hugh Grant</td>
    </tr>
    <tr>
      <th>1392</th>
      <td>0.000000</td>
      <td>supporting_Hugh Jackman</td>
    </tr>
    <tr>
      <th>1393</th>
      <td>0.000000</td>
      <td>supporting_Hugo Weaving</td>
    </tr>
  </tbody>
</table>
</div>



It looks like there are only five effective features, and they make sense. The more budget spent on a film, the more revenue it is likely to pull in particularly if a lot of that budget is spent on marketing. The higher the number of votes a movie gets the more people that are likely to have seen it, and movies that are rated highly are likely to be more popular, too. Runtime, the most important feature in predicting a movie rating (surprisingly) is also very important here, moreso than whether or not the movie is part of a franchise. The other features look like they were equally irrelevant, which is why they are displaying in alphabetical order.

### Bagged decision trees
A bagged decision tree with 30 estimators was the best performing for predicting movie ratings, so we'll see how they work here.


```python
from sklearn.ensemble import BaggingRegressor
```


```python
est = list(range(10, 110, 10))

for n in est:
    bag_dt = BaggingRegressor(DecisionTreeRegressor(), n_estimators=n, bootstrap=True, oob_score=True, random_state=42)
    score = cross_val_score(bag_dt, X_train, y_train, cv=9, scoring='neg_mean_squared_error')
    bag_dt.fit(X_train, y_train)
    print("Cross-validated score for bag_dt",n,": ",'${:,.2f}'.format(np.mean(np.sqrt(-score))))
    print("bag_dt testing RMSE for",n,": ",'${:,.2f}'.format(np.sqrt(mean_squared_error(y_test, bag_dt.predict(X_test)))))
    print("\n")    
```

    Cross-validated score for bag_dt 10 :  $96,369,405.90
    bag_dt testing RMSE for 10 :  $147,466,549.60


    Cross-validated score for bag_dt 20 :  $94,244,844.99
    bag_dt testing RMSE for 20 :  $143,083,337.29


    Cross-validated score for bag_dt 30 :  $92,964,547.90
    bag_dt testing RMSE for 30 :  $141,690,486.49


    Cross-validated score for bag_dt 40 :  $93,410,084.52
    bag_dt testing RMSE for 40 :  $141,609,089.50


    Cross-validated score for bag_dt 50 :  $93,759,924.01
    bag_dt testing RMSE for 50 :  $141,383,385.32


    Cross-validated score for bag_dt 60 :  $94,352,917.84
    bag_dt testing RMSE for 60 :  $140,862,076.01


    Cross-validated score for bag_dt 70 :  $94,342,565.53
    bag_dt testing RMSE for 70 :  $140,891,401.66


    Cross-validated score for bag_dt 80 :  $94,279,718.41
    bag_dt testing RMSE for 80 :  $141,075,773.87


    Cross-validated score for bag_dt 90 :  $94,209,568.97
    bag_dt testing RMSE for 90 :  $140,745,532.03


    Cross-validated score for bag_dt 100 :  $94,204,738.96
    bag_dt testing RMSE for 100 :  $140,817,063.73






### Random forest


```python
from sklearn.ensemble import RandomForestRegressor
```


```python
for n in est:
    rf = RandomForestRegressor(n_estimators=n, random_state=42)
    score = cross_val_score(rf, X_train, y_train, cv=9, scoring='neg_mean_squared_error')
    rf.fit(X_train, y_train)
    print("rf training RMSE for",n,": ",'${:,.2f}'.format(np.mean(np.sqrt(-score))))
    print("rf testing RMSE for",n,": ",'${:,.2f}'.format(np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))))
    print("\n")
```

    rf training RMSE for 10 :  $96,126,086.00
    rf testing RMSE for 10 :  $145,609,700.84


    rf training RMSE for 20 :  $94,488,846.22
    rf testing RMSE for 20 :  $142,563,720.02


    rf training RMSE for 30 :  $93,122,073.84
    rf testing RMSE for 30 :  $141,203,091.55


    rf training RMSE for 40 :  $93,717,575.79
    rf testing RMSE for 40 :  $140,952,788.09


    rf training RMSE for 50 :  $93,877,596.50
    rf testing RMSE for 50 :  $140,933,224.55


    rf training RMSE for 60 :  $94,238,396.30
    rf testing RMSE for 60 :  $140,443,308.86


    rf training RMSE for 70 :  $94,400,362.21
    rf testing RMSE for 70 :  $140,051,436.45


    rf training RMSE for 80 :  $94,384,216.13
    rf testing RMSE for 80 :  $140,178,093.10


    rf training RMSE for 90 :  $94,456,911.35
    rf testing RMSE for 90 :  $139,893,143.02


    rf training RMSE for 100 :  $94,439,537.97
    rf testing RMSE for 100 :  $140,048,838.22




The differences are too different between the numbers of estimators in the random forests. The model I perceive to work the best is the *rf* with 90 estimators. I'll analyse the feature importances again, using this model this time.


```python
rf = RandomForestRegressor(n_estimators=90, random_state=42)
rf.fit(X_train, y_train)
pd.DataFrame({'feature':X_train.columns, 'coefficients':rf.feature_importances_}).sort_values(by='coefficients', axis=0, ascending=False).head(10)
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coefficients</th>
      <th>feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>250</th>
      <td>0.410142</td>
      <td>vote_count</td>
    </tr>
    <tr>
      <th>247</th>
      <td>0.360643</td>
      <td>budget</td>
    </tr>
    <tr>
      <th>248</th>
      <td>0.027677</td>
      <td>runtime</td>
    </tr>
    <tr>
      <th>249</th>
      <td>0.019103</td>
      <td>vote_average</td>
    </tr>
    <tr>
      <th>251</th>
      <td>0.018135</td>
      <td>belongs_to_collection</td>
    </tr>
    <tr>
      <th>263</th>
      <td>0.010293</td>
      <td>Fantasy</td>
    </tr>
    <tr>
      <th>253</th>
      <td>0.006738</td>
      <td>Adventure</td>
    </tr>
    <tr>
      <th>275</th>
      <td>0.005906</td>
      <td>Science Fiction</td>
    </tr>
    <tr>
      <th>280</th>
      <td>0.004087</td>
      <td>Thriller</td>
    </tr>
    <tr>
      <th>2030</th>
      <td>0.003346</td>
      <td>supporting_Toni Collette</td>
    </tr>
  </tbody>
</table>
</div>



These feature importances are slightly different, although no less interesting. Vote count is considered the most important here, with budget and runtime also being important. Interestingly, average vote is considered less important than in the decision tree. Genres are given much more importance here than before.

### Conclusion
The best performing model, and the one I will choose for my interactive interface, will be the random forest model with 90 estimators. This choice is based on it producing the lowest testing error.
