<!DOCTYPE html>
<html lang="en">
  
  <head>
  <meta charset="UTF-8">
  <title>Jasmine Holdsworth</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Jasmine Holdsworth</h1>
  <h2 class="project-tagline"><html>I am a Senior Data Analyst/Data Scientist based in London. I love R, Python, and anything data-related. I have previously worked at <b>Stack Overflow</b> and <b>DAZN</b>. I currently teach at <b>General Assembly</b> and work at <b>Expedia</b>.</html></h2>
  <a href="/aboutme/" class="btn">About Me</a>
  <a href="/" class="btn">Projects</a>
  <a href="https://github.com/JazPeng" target="_blank" class="btn">GitHub</a>
  <a href="https://twitter.com/StackJaz" target="_blank" class="btn">Twitter</a>
  <a href="https://www.linkedin.com/in/jasmine-pengelly-a59b5552/" target="_blank" class="btn">LinkedIn</a>
</section>


    <section class="main-content">
      
      <h1 id="predicting-profit-generated-by-movies"><center>Predicting profit generated by movies</center></h1>
<h2 id="python"><center>Python</center></h2>

<p>In my last post, I tested several models that predicted movie ratings. This time, I’ll try and predict the gross profit a movie might generate based on the same features. The aim is to create a Flask app that will allow a user to see the predicted rating and gross profit for a movie they create based on certain feature choices (ie. cast, director, genre).</p>

<p>Since all the data cleaning was done in my last blog post, I can move straight into the exploratory data analysis.</p>

<h2 id="set-up-and-import-data">Set up and import data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span> <span class="k">as</span> <span class="n">lm</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ensemble</span><span class="p">,</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">chained_assignment</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_columns'</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_rows'</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span>
    <span class="s">'figure.figsize'</span><span class="p">:</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="s">'font.size'</span><span class="p">:</span> <span class="mi">14</span>
<span class="p">})</span>

<span class="c"># Set palette</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s">"husl"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">movies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"/Users/jasminepengelly/Desktop/projects/predicting_movie/movies_wo_dir.csv"</span><span class="p">)</span>
<span class="n">movies</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"Unnamed: 0"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">movies</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies</span><span class="p">[</span><span class="s">"revenue"</span><span class="p">]</span> <span class="o">-</span> <span class="n">movies</span><span class="p">[</span><span class="s">"budget"</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">movies</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>id</th>
      <th>budget</th>
      <th>revenue</th>
      <th>runtime</th>
      <th>vote_average</th>
      <th>vote_count</th>
      <th>belongs_to_collection</th>
      <th>Action</th>
      <th>Adventure</th>
      <th>Animation</th>
      <th>Aniplex</th>
      <th>BROSTA TV</th>
      <th>Carousel Productions</th>
      <th>Comedy</th>
      <th>Crime</th>
      <th>Documentary</th>
      <th>Drama</th>
      <th>Family</th>
      <th>Fantasy</th>
      <th>Foreign</th>
      <th>GoHands</th>
      <th>History</th>
      <th>Horror</th>
      <th>Mardock Scramble Production Committee</th>
      <th>Music</th>
      <th>Mystery</th>
      <th>Odyssey Media</th>
      <th>Pulser Productions</th>
      <th>Rogue State</th>
      <th>Romance</th>
      <th>Science Fiction</th>
      <th>Sentai Filmworks</th>
      <th>TV Movie</th>
      <th>Telescene Film Group Productions</th>
      <th>The Cartel</th>
      <th>Thriller</th>
      <th>Vision View Entertainment</th>
      <th>War</th>
      <th>Western</th>
      <th>lead</th>
      <th>supporting</th>
      <th>dir_count</th>
      <th>gross_profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Toy Story</td>
      <td>862</td>
      <td>30000000.0</td>
      <td>373554033.0</td>
      <td>81.0</td>
      <td>7.7</td>
      <td>5415.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Tom Hanks</td>
      <td>Tim Allen</td>
      <td>5</td>
      <td>343554033.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jumanji</td>
      <td>8844</td>
      <td>65000000.0</td>
      <td>262797249.0</td>
      <td>104.0</td>
      <td>6.9</td>
      <td>2413.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Robin Williams</td>
      <td>Jonathan Hyde</td>
      <td>7</td>
      <td>197797249.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heat</td>
      <td>949</td>
      <td>60000000.0</td>
      <td>187436818.0</td>
      <td>170.0</td>
      <td>7.7</td>
      <td>1886.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Al Pacino</td>
      <td>Robert De Niro</td>
      <td>10</td>
      <td>127436818.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sudden Death</td>
      <td>9091</td>
      <td>35000000.0</td>
      <td>64350171.0</td>
      <td>106.0</td>
      <td>5.5</td>
      <td>174.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Jean-Claude Van Damme</td>
      <td>Powers Boothe</td>
      <td>10</td>
      <td>29350171.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>GoldenEye</td>
      <td>710</td>
      <td>58000000.0</td>
      <td>352194034.0</td>
      <td>130.0</td>
      <td>6.6</td>
      <td>1194.0</td>
      <td>1</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>Pierce Brosnan</td>
      <td>Sean Bean</td>
      <td>8</td>
      <td>294194034.0</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="exploratory-data-analysis">Exploratory data analysis</h2>

<p>From my previous analysis, I know there is a relatively high correlation between <em>budget</em>, <em>revenue</em> and <em>vote_count</em>. This time around I’ll focus on the relationships between <em>revenue</em> and the other variables.</p>

<p>First, I’ll define the variables that I’m using.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s">'budget'</span><span class="p">,</span> <span class="s">'runtime'</span><span class="p">,</span> <span class="s">'vote_count'</span><span class="p">,</span> <span class="s">'belongs_to_collection'</span><span class="p">,</span> <span class="s">'Action'</span><span class="p">,</span> <span class="s">'Adventure'</span><span class="p">,</span> 
              <span class="s">'Animation'</span><span class="p">,</span> <span class="s">'Aniplex'</span><span class="p">,</span> <span class="s">'BROSTA TV'</span><span class="p">,</span> <span class="s">'Carousel Productions'</span><span class="p">,</span> <span class="s">'Comedy'</span><span class="p">,</span> <span class="s">'Crime'</span><span class="p">,</span> <span class="s">'Documentary'</span><span class="p">,</span> <span class="s">'Drama'</span><span class="p">,</span>
              <span class="s">'Family'</span><span class="p">,</span> <span class="s">'Fantasy'</span><span class="p">,</span> <span class="s">'Foreign'</span><span class="p">,</span> <span class="s">'GoHands'</span><span class="p">,</span> <span class="s">'History'</span><span class="p">,</span> <span class="s">'Horror'</span><span class="p">,</span> <span class="s">'Mardock Scramble Production Committee'</span><span class="p">,</span>
              <span class="s">'Music'</span><span class="p">,</span> <span class="s">'Mystery'</span><span class="p">,</span> <span class="s">'Odyssey Media'</span><span class="p">,</span> <span class="s">'Pulser Productions'</span><span class="p">,</span> <span class="s">'Rogue State'</span><span class="p">,</span> <span class="s">'Romance'</span><span class="p">,</span> <span class="s">'Science Fiction'</span><span class="p">,</span>
              <span class="s">'Sentai Filmworks'</span><span class="p">,</span> <span class="s">'TV Movie'</span><span class="p">,</span> <span class="s">'Telescene Film Group Productions'</span><span class="p">,</span> <span class="s">'The Cartel'</span><span class="p">,</span> <span class="s">'Thriller'</span><span class="p">,</span> 
              <span class="s">'Vision View Entertainment'</span><span class="p">,</span> <span class="s">'War'</span><span class="p">,</span> <span class="s">'Western'</span><span class="p">,</span> <span class="s">'lead'</span><span class="p">,</span> <span class="s">'supporting'</span><span class="p">,</span> <span class="s">'vote_average'</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="s">'gross_profit'</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">movies</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'dir_count'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">220</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">7</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1aabd240&gt;
</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/JazPeng/assets/master/movies/profit_corr.png" alt="Correlation Matrix" /></p>

<p>My response variable, <em>gross_profit</em>, is highly correlated with <em>budget</em>, <em>revenue</em> and <em>vote_ count</em>. <em>budget</em> and <em>revenue</em> make sense, since the three are directly related, but <em>vote_ count</em> is less intuitive - perhaps more votes are to be expected on popular films, and films with a high budget or that make large revenue get more votes.</p>

<p>Within my features, I already identified the correlation between <em>Family</em> and <em>Animation</em>, and <em>vote_count</em> and <em>budget</em>, are not significant enough to worry about. This bodes well for my models - there will be no multicollinearity and there is no need for PCA here.</p>

<h3 id="highest-revenue-films">Highest revenue films</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">high_rev</span> <span class="o">=</span> <span class="n">movies</span><span class="p">[[</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'revenue'</span><span class="p">]]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'revenue'</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">high_rev</span><span class="p">[</span><span class="s">'revenue'</span><span class="p">]</span> <span class="o">=</span> <span class="n">high_rev</span><span class="p">[</span><span class="s">'revenue'</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
<span class="n">high_rev</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1439</th>
      <td>Avatar</td>
      <td>$2,787,965,087.00</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>Star Wars: The Force Awakens</td>
      <td>$2,068,223,624.00</td>
    </tr>
    <tr>
      <th>328</th>
      <td>Titanic</td>
      <td>$1,845,034,188.00</td>
    </tr>
    <tr>
      <th>1778</th>
      <td>Furious 7</td>
      <td>$1,506,249,360.00</td>
    </tr>
    <tr>
      <th>1540</th>
      <td>Harry Potter and the Deathly Hallows: Part 2</td>
      <td>$1,342,000,000.00</td>
    </tr>
    <tr>
      <th>1875</th>
      <td>Beauty and the Beast</td>
      <td>$1,262,886,337.00</td>
    </tr>
    <tr>
      <th>1881</th>
      <td>The Fate of the Furious</td>
      <td>$1,238,764,765.00</td>
    </tr>
    <tr>
      <th>1535</th>
      <td>Transformers: Dark of the Moon</td>
      <td>$1,123,746,996.00</td>
    </tr>
    <tr>
      <th>994</th>
      <td>The Lord of the Rings: The Return of the King</td>
      <td>$1,118,888,979.00</td>
    </tr>
    <tr>
      <th>1614</th>
      <td>Skyfall</td>
      <td>$1,108,561,013.00</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="highest-grossing-films">Highest grossing films</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">high_gp</span> <span class="o">=</span> <span class="n">movies</span><span class="p">[[</span><span class="s">'title'</span><span class="p">,</span> <span class="s">"gross_profit"</span><span class="p">]]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">"gross_profit"</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">high_gp</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span> <span class="o">=</span> <span class="n">high_gp</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
<span class="n">high_gp</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>gross_profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1439</th>
      <td>Avatar</td>
      <td>$2,550,965,087.00</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>Star Wars: The Force Awakens</td>
      <td>$1,823,223,624.00</td>
    </tr>
    <tr>
      <th>328</th>
      <td>Titanic</td>
      <td>$1,645,034,188.00</td>
    </tr>
    <tr>
      <th>1778</th>
      <td>Furious 7</td>
      <td>$1,316,249,360.00</td>
    </tr>
    <tr>
      <th>1540</th>
      <td>Harry Potter and the Deathly Hallows: Part 2</td>
      <td>$1,217,000,000.00</td>
    </tr>
    <tr>
      <th>1875</th>
      <td>Beauty and the Beast</td>
      <td>$1,102,886,337.00</td>
    </tr>
    <tr>
      <th>994</th>
      <td>The Lord of the Rings: The Return of the King</td>
      <td>$1,024,888,979.00</td>
    </tr>
    <tr>
      <th>1881</th>
      <td>The Fate of the Furious</td>
      <td>$988,764,765.00</td>
    </tr>
    <tr>
      <th>1535</th>
      <td>Transformers: Dark of the Moon</td>
      <td>$928,746,996.00</td>
    </tr>
    <tr>
      <th>1614</th>
      <td>Skyfall</td>
      <td>$908,561,013.00</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="lowest-revenue-films">Lowest revenue films</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">low_rev</span> <span class="o">=</span> <span class="n">movies</span><span class="p">[[</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'revenue'</span><span class="p">]]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'revenue'</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">low_rev</span><span class="p">[</span><span class="s">'revenue'</span><span class="p">]</span> <span class="o">=</span> <span class="n">low_rev</span><span class="p">[</span><span class="s">'revenue'</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
<span class="n">low_rev</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>576</th>
      <td>Angela's Ashes</td>
      <td>$13.00</td>
    </tr>
    <tr>
      <th>1271</th>
      <td>Death at a Funeral</td>
      <td>$46.00</td>
    </tr>
    <tr>
      <th>628</th>
      <td>The Idiots</td>
      <td>$7,235.00</td>
    </tr>
    <tr>
      <th>1604</th>
      <td>5 Days of War</td>
      <td>$17,479.00</td>
    </tr>
    <tr>
      <th>590</th>
      <td>City Lights</td>
      <td>$19,181.00</td>
    </tr>
    <tr>
      <th>1464</th>
      <td>Valhalla Rising</td>
      <td>$30,638.00</td>
    </tr>
    <tr>
      <th>480</th>
      <td>Following</td>
      <td>$48,482.00</td>
    </tr>
    <tr>
      <th>1678</th>
      <td>The Canyons</td>
      <td>$56,825.00</td>
    </tr>
    <tr>
      <th>1628</th>
      <td>Byzantium</td>
      <td>$89,237.00</td>
    </tr>
    <tr>
      <th>1796</th>
      <td>Manglehorn</td>
      <td>$143,101.00</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="biggest-loss">Biggest loss</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">high_gp</span> <span class="o">=</span> <span class="n">movies</span><span class="p">[[</span><span class="s">'title'</span><span class="p">,</span> <span class="s">"gross_profit"</span><span class="p">]]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">"gross_profit"</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">high_gp</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span> <span class="o">=</span> <span class="n">high_gp</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
<span class="n">high_gp</span>
</code></pre></div></div>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>gross_profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1673</th>
      <td>The Lone Ranger</td>
      <td>$-165,710,090.00</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>The Alamo</td>
      <td>$-119,180,039.00</td>
    </tr>
    <tr>
      <th>1884</th>
      <td>Valerian and the City of a Thousand Planets</td>
      <td>$-107,447,384.00</td>
    </tr>
    <tr>
      <th>513</th>
      <td>The 13th Warrior</td>
      <td>$-98,301,101.00</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Cutthroat Island</td>
      <td>$-87,982,678.00</td>
    </tr>
    <tr>
      <th>1365</th>
      <td>Australia</td>
      <td>$-80,445,998.00</td>
    </tr>
    <tr>
      <th>578</th>
      <td>Supernova</td>
      <td>$-75,171,919.00</td>
    </tr>
    <tr>
      <th>1080</th>
      <td>A Sound of Thunder</td>
      <td>$-74,010,360.00</td>
    </tr>
    <tr>
      <th>1128</th>
      <td>The Great Raid</td>
      <td>$-69,833,498.00</td>
    </tr>
    <tr>
      <th>1674</th>
      <td>R.I.P.D.</td>
      <td>$-68,351,500.00</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="import-directors-and-get-dummy-variables">Import directors and get dummy variables</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">directors</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"/Users/jasminepengelly/Desktop/projects/predicting_movie/director_dummies.csv"</span><span class="p">)</span>
<span class="n">directors</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"Unnamed: 0"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">final</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">directors</span><span class="p">,</span> <span class="n">movies</span><span class="p">,</span> <span class="n">left_on</span> <span class="o">=</span> <span class="s">'index'</span><span class="p">,</span> <span class="n">right_on</span> <span class="o">=</span> <span class="s">'id'</span><span class="p">)</span>
<span class="n">final</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"index"</span><span class="p">,</span> <span class="s">"title"</span><span class="p">,</span> <span class="s">"dir_count"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">final</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'lead'</span><span class="p">,</span> <span class="s">'supporting'</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="pre-processing">Pre-processing</h3>
<p>Since the final product of this modelling is to produce a Flask app that allows someone to input factors about a film before it’s produced to get the rating and the gross profit generated, some features will have to be dropped. For example, a user would not know the <em>vote_count</em> before the film is created. Some of the features I am removing are the most correlated with the response variable so I will be losing some of the predictive power.</p>

<p>I’ll begin by defining my train-test split. Then, as with my previous blog post, I’ll standardise the remaining predictive variables since it’s good practice for working with linear regression models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">dummies</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"revenue"</span><span class="p">,</span> <span class="s">"vote_count"</span><span class="p">,</span> <span class="s">"gross_profit"</span><span class="p">,</span> <span class="s">"vote_average"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dummies</span><span class="p">[</span><span class="s">"gross_profit"</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Length of training sets:"</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Length of testing sets:"</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Length of training sets: 1320 567
Length of testing sets: 1320 567
</code></pre></div></div>

<h3 id="modelling">Modelling</h3>

<h4 id="baseline-score">Baseline score</h4>
<p>I need a baseline score with which to compare the scores for all my models moving forward. This score will represent the score one would get if they were just to predict the mean value for <em>y</em>. If my model outperforms this score, I know it is doing well.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Dumb model RMSE: "</span><span class="p">,</span><span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mean</span><span class="p">))))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dumb model RMSE:  $226,516,599.51
</code></pre></div></div>

<p>$226 million will be the benchmark RMSE for my model’s success. It’s still a very wide margin to be out by, so I’m hoping I can beat this.</p>

<h4 id="function-to-generate-model-scores">Function to generate model scores</h4>
<p>Since I’ll be trying out many different models, I’ll build a function that returns all the information for efficiency. I’ll create one function for simple models and another for models utilising regularisation.</p>

<p>If this were a function I was using regularly, I would put it in a script and import it. However, I wanted it explicitly stated here for you to see.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Function to return simple model metrics</span>
<span class="k">def</span> <span class="nf">get_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">parametric</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s">"""This function takes the train-test splits as arguments, as well as the algorithm 
    being used, and returns the training score, the test score (both RMSE), the 
    cross-validated scores and the mean cross-validated score. It also returns the appropriate 
    feature importances depending on whether the optional argument 'parametric' is equal to 
    True or False."""</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">'Training RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">))))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Testing RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred</span><span class="p">))))</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Cross-validated RMSEs:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Mean cross-validated RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))))</span>
    
    <span class="k">if</span> <span class="n">parametric</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">))),</span> 
                 <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Feature'</span><span class="p">,</span> <span class="s">'Coef'</span><span class="p">,</span> <span class="s">'Abs Coef'</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Abs Coef'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)),</span> 
                 <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Feature'</span><span class="p">,</span> <span class="s">'Importance'</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Function to return regularised model metrics</span>
<span class="k">def</span> <span class="nf">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">grid_params</span><span class="p">,</span> <span class="n">parametric</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s">"""This function takes the train-test splits as arguments, as well as the algorithm being 
    used and the parameters, and returns the best cross-validated training score, the test 
    score, the best performing model and it's parameters, and the feature importances."""</span>
    
    <span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                              <span class="n">grid_params</span><span class="p">,</span>
                              <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
    
    <span class="n">gridsearch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Best parameters:'</span><span class="p">,</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Cross-validated score on test data:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">gridsearch</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)))</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Testing RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))))</span>
    
    <span class="k">if</span> <span class="n">parametric</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">best_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">))),</span> 
                 <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Feature'</span><span class="p">,</span> <span class="s">'Coef'</span><span class="p">,</span> <span class="s">'Abs Coef'</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Abs Coef'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">best_model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)),</span> 
                 <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Feature'</span><span class="p">,</span> <span class="s">'Importance'</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">best_model</span>
</code></pre></div></div>

<h4 id="linear-regression">Linear regression</h4>
<h5 id="simple">Simple</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span> <span class="o">=</span> <span class="n">get_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">lr</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE: $43,093,674.65
Testing RMSE: $6,850,145,181,265,346,691,072.00
Cross-validated RMSEs: [4.17892339e+21 9.90531764e+21 1.53491007e+22 1.13727100e+22
 5.58558345e+21]
Mean cross-validated RMSE: $10,116,431,047,916,374,720,512.00
                                    Feature          Coef      Abs Coef
1088              supporting_Bijou Phillips  1.347614e+21  1.347614e+21
276        Telescene Film Group Productions -1.259300e+21  1.259300e+21
266   Mardock Scramble Production Committee  1.202241e+21  1.202241e+21
665                         lead_Judi Dench -1.150649e+21  1.150649e+21
1951                  supporting_Seth Green -1.078695e+21  1.078695e+21
584                        lead_James Woods -1.075888e+21  1.075888e+21
428                   lead_Cuba Gooding Jr.  1.031542e+21  1.031542e+21
25                              Bill Condon  1.029315e+21  1.029315e+21
1212                 supporting_Dan Stevens -1.012743e+21  1.012743e+21
1011            supporting_Adrienne Barbeau -9.823532e+20  9.823532e+20





LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</code></pre></div></div>

<p>Both my scores are terrible here, and the vast difference between the scores show the level of overfitting. Time for some regularisation.</p>

<h5 id="regularised---ridge">Regularised - Ridge</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ridge</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">()</span>

<span class="n">ridge_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
               <span class="s">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">],</span>
               <span class="s">'solver'</span><span class="p">:</span> <span class="p">[</span><span class="s">'auto'</span><span class="p">,</span> <span class="s">'svd'</span><span class="p">,</span> <span class="s">'cholesky'</span><span class="p">,</span> <span class="s">'lsqr'</span><span class="p">,</span> <span class="s">'sparse_cg'</span><span class="p">,</span> <span class="s">'sag'</span><span class="p">,</span> <span class="s">'saga'</span><span class="p">]}</span>

<span class="n">ridge_model</span> <span class="o">=</span> <span class="n">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ridge</span><span class="p">,</span> <span class="n">ridge_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 70 candidates, totalling 350 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.3s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   35.6s
[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:  1.1min finished


Best parameters: {'alpha': 700.0, 'fit_intercept': True, 'solver': 'saga'}
Cross-validated score on test data: $0.36
Testing RMSE: $185,680,100.81
                       Feature          Coef      Abs Coef
249      belongs_to_collection  2.131550e+07  2.131550e+07
247                     budget  2.086358e+07  2.086358e+07
82                George Lucas  1.426045e+07  1.426045e+07
248                    runtime  1.330278e+07  1.330278e+07
437      lead_Daniel Radcliffe  1.128897e+07  1.128897e+07
1918   supporting_Rupert Grint  1.100804e+07  1.100804e+07
1976  supporting_Stanley Tucci  9.935829e+06  9.935829e+06
1395   supporting_Ian McKellen  9.889183e+06  9.889183e+06
251                  Adventure  9.849955e+06  9.849955e+06
491           lead_Emma Watson  9.219124e+06  9.219124e+06
</code></pre></div></div>

<p>This test score is already better than the baseline, so I know we are moving in the right direction. With the most predictive features removed, it’s interesting to see that ‘belongs_to_collection’ seems to be more influencial than budget.</p>

<h5 id="regularised---lasso">Regularised - Lasso</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">lasso_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
               <span class="s">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]}</span>

<span class="n">lasso_model</span> <span class="o">=</span> <span class="n">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lasso</span><span class="p">,</span> <span class="n">lasso_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 10 candidates, totalling 50 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.6s


Best parameters: {'alpha': 10000000000.0, 'fit_intercept': True}
Cross-validated score on test data: $0.02
Testing RMSE: $226,516,599.51
                        Feature  Coef  Abs Coef
0                 Aaron Seltzer  -0.0       0.0
1402   supporting_Irene Miracle   0.0       0.0
1400  supporting_Ingrid Bergman   0.0       0.0
1399    supporting_Ichirō Nagai  -0.0       0.0
1398        supporting_Ice Cube   0.0       0.0
1397     supporting_Iben Hjejle  -0.0       0.0
1396     supporting_Ian McShane   0.0       0.0
1395    supporting_Ian McKellen   0.0       0.0
1394   supporting_Ian McDiarmid   0.0       0.0
1393        supporting_Ian Holm   0.0       0.0


[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished
</code></pre></div></div>

<p>After a lot of tuning and increasing the alpha, lasso still didn’t perform as well as ridge. The coefficients also make less intuitive sense.</p>

<h5 id="regularised---elasticnet">Regularised - ElasticNet</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">elastic</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">ElasticNet</span><span class="p">()</span>

<span class="n">elastic_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                 <span class="s">'l1_ratio'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                 <span class="s">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]}</span>

<span class="n">elastic_model</span> <span class="o">=</span> <span class="n">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">elastic</span><span class="p">,</span> 
                                          <span class="n">elastic_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.7s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   19.4s
[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   34.3s
[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   53.1s


Best parameters: {'alpha': 2.0, 'fit_intercept': True, 'l1_ratio': 0.65}
Cross-validated score on test data: $0.36
Testing RMSE: $186,283,469.11
                       Feature          Coef      Abs Coef
247                     budget  1.991908e+07  1.991908e+07
249      belongs_to_collection  1.967256e+07  1.967256e+07
82                George Lucas  1.289770e+07  1.289770e+07
248                    runtime  1.227358e+07  1.227358e+07
437      lead_Daniel Radcliffe  1.076488e+07  1.076488e+07
1918   supporting_Rupert Grint  1.046807e+07  1.046807e+07
251                  Adventure  9.455739e+06  9.455739e+06
1395   supporting_Ian McKellen  9.207659e+06  9.207659e+06
1976  supporting_Stanley Tucci  9.097251e+06  9.097251e+06
1212    supporting_Dan Stevens  8.682729e+06  8.682729e+06


[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.1min finished
</code></pre></div></div>

<p>This gives me very similar results to the ridge linear regression, but still doesn’t perform as well. So far, the ridge linear regression is the best performing.</p>

<h4 id="tree-models">Tree models</h4>
<h5 id="simple-decision-tree">Simple decision tree</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dt</span> <span class="o">=</span> <span class="n">get_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(),</span> 
                       <span class="n">parametric</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">dt</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE: $0.00
Testing RMSE: $189,435,992.34
Cross-validated RMSEs: [1.62986560e+08 1.50676461e+08 1.16390236e+08 1.28971798e+08
 1.60756615e+08]
Mean cross-validated RMSE: $145,114,517.27
                       Feature  Importance
247                     budget    0.330288
249      belongs_to_collection    0.124512
248                    runtime    0.096301
491           lead_Emma Watson    0.026973
742           lead_Mark Hamill    0.013669
37                Bryan Singer    0.012596
799            lead_Neel Sethi    0.012294
42           Christopher Nolan    0.011744
278                   Thriller    0.011406
2028  supporting_Toni Collette    0.010859





DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,
           max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=None, splitter='best')
</code></pre></div></div>

<p>Simple decision trees tend to overfit, so I am not surprised by the train and test scores being what they are. However, I am surprised that the cross-validated score is quite good.</p>

<h5 id="random-forest">Random forest</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf</span> <span class="o">=</span> <span class="n">get_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">(),</span> 
                       <span class="n">parametric</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">rf</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE: $51,290,496.58
Testing RMSE: $171,985,754.15
Cross-validated RMSEs: [1.30170546e+08 1.29842827e+08 9.17430304e+07 1.19111377e+08
 1.27713356e+08]
Mean cross-validated RMSE: $120,597,293.25
                       Feature  Importance
247                     budget    0.324819
249      belongs_to_collection    0.119175
248                    runtime    0.073327
25                 Bill Condon    0.012158
226           Steven Spielberg    0.012097
742           lead_Mark Hamill    0.011958
2028  supporting_Toni Collette    0.011653
1395   supporting_Ian McKellen    0.010731
799            lead_Neel Sethi    0.010293
251                  Adventure    0.009515





RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
</code></pre></div></div>

<p>The best performing model so far, with feature importances that make intuitive sense.</p>

<h5 id="regularised-random-forest">Regularised Random forest</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rrf</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="n">rrf_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'bootstrap'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">],</span>
             <span class="s">'max_depth'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
             <span class="s">'min_samples_split'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
             <span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>

<span class="n">rrf_model</span> <span class="o">=</span> <span class="n">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">rrf</span><span class="p">,</span> <span class="n">rrf_params</span><span class="p">,</span>
                                     <span class="n">parametric</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 150 candidates, totalling 750 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   16.4s
[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   42.7s
[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed:  1.7min finished


Best parameters: {'bootstrap': False, 'max_depth': 5.0, 'min_samples_split': 0.1, 'n_estimators': 10}
Cross-validated score on test data: $0.35
Testing RMSE: $188,255,673.77
                       Feature  Importance
247                     budget    0.628325
249      belongs_to_collection    0.270686
2028  supporting_Toni Collette    0.023607
248                    runtime    0.015528
742           lead_Mark Hamill    0.014858
1371  supporting_Harrison Ford    0.014858
226           Steven Spielberg    0.013352
678      lead_Kathryn Beaumont    0.009393
2046   supporting_Verna Felton    0.009393
1395   supporting_Ian McKellen    0.000000
</code></pre></div></div>

<p>A good test score, but not quite as good as the random forest with the default parameters.</p>

<h5 id="bagged-decision-trees">Bagged decision trees</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bagdt</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">BaggingRegressor</span><span class="p">()</span>
<span class="n">bagdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Training RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">bagdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Testing RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">bagdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))))</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">bagdt</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Cross-validated RMSEs:'</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Mean cross-validated RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE: $47,551,713.19
Testing RMSE: $167,557,918.72
Cross-validated RMSEs: [1.61524815e+16 1.63382135e+16 8.80421032e+15 1.40081532e+16
 1.70218650e+16]
Mean cross-validated RMSE: $14,464,984,700,217,268.00
</code></pre></div></div>

<p>I am disappointed at the mean cross-validated score here - this model won’t generalise well.</p>

<h4 id="support-vector-machine">Support Vector Machine</h4>
<h5 id="linearsvr">LinearSVR</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lin</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVR</span><span class="p">()</span> 

<span class="n">lin_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'C'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="s">'loss'</span><span class="p">:</span> <span class="p">[</span><span class="s">'epsilon_insensitive'</span><span class="p">,</span><span class="s">'squared_epsilon_insensitive'</span><span class="p">],</span>
    <span class="s">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span><span class="bp">False</span><span class="p">],</span>
    <span class="s">'max_iter'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">lin_model</span> <span class="o">=</span> <span class="n">regularised_model_metrics</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lin</span><span class="p">,</span> <span class="n">lin_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 20 candidates, totalling 100 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.6s
[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   53.0s finished


Best parameters: {'C': 0.001, 'fit_intercept': True, 'loss': 'squared_epsilon_insensitive', 'max_iter': 1000}
Cross-validated score on test data: $0.07
Testing RMSE: $188,783,310.28
                       Feature          Coef      Abs Coef
249      belongs_to_collection  2.347037e+07  2.347037e+07
247                     budget  2.172464e+07  2.172464e+07
82                George Lucas  1.620963e+07  1.620963e+07
248                    runtime  1.470311e+07  1.470311e+07
437      lead_Daniel Radcliffe  1.180886e+07  1.180886e+07
1918   supporting_Rupert Grint  1.154390e+07  1.154390e+07
1976  supporting_Stanley Tucci  1.089841e+07  1.089841e+07
1395   supporting_Ian McKellen  1.066900e+07  1.066900e+07
251                  Adventure  1.028434e+07  1.028434e+07
2028  supporting_Toni Collette  1.008356e+07  1.008356e+07
</code></pre></div></div>

<p>Although the test score is below baseline, the test score isn’t as good as the random forest.</p>

<h5 id="rbf">RBF</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rbf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>

<span class="n">rbf_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'C'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="s">'gamma'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="s">'kernel'</span><span class="p">:</span> <span class="p">[</span><span class="s">'rbf'</span><span class="p">]}</span>

<span class="n">rbf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rbf</span><span class="p">,</span> <span class="n">rbf_params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="n">rbf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Best parameters:'</span><span class="p">,</span> <span class="n">rbf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">rbf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Testing RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rbf</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 25 candidates, totalling 125 fits


[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min
[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.1min finished


Best parameters: {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}
Training RMSE: $0.14
Testing RMSE: $240,436,736.27
</code></pre></div></div>

<p>This has performed worse than the LinearSVR, so I won’t be using this.</p>

<h5 id="poly">Poly</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">poly</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'poly'</span><span class="p">)</span>

<span class="n">poly_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'C'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="s">'gamma'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="s">'degree'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">]}</span>

<span class="n">poly</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">poly_params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="n">poly</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Best parameters:'</span><span class="p">,</span> <span class="n">poly</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">poly</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Testing RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">poly</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 9 candidates, totalling 45 fits


[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.5min finished


Best parameters: {'C': 0.31622776601683794, 'degree': 2, 'gamma': 100.0}
Training RMSE: $0.14
Testing RMSE: $202,171,501.80
</code></pre></div></div>

<p>I did play with including 3 as a degree hyperparameter, but the gridsearch took ages to run and the results didn’t improve much.</p>

<h2 id="conclusion">Conclusion</h2>
<p>The best performing model is the random forest. I will pickle it, as well as exporting the scaled features as csv, and use them in my Flask app.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">])</span>
<span class="n">y_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_scaled</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">"X_profit.csv"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_concat</span><span class="p">)</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_concat</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Cross-validated RMSEs:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Mean cross-validated RMSE:'</span><span class="p">,</span> <span class="s">'${:,.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cross-validated RMSEs: [1.25429824e+08 9.88043543e+07 1.11233629e+08 1.53454944e+08
 1.52458683e+08]
Mean cross-validated RMSE: $128,276,286.95
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'model_profit.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>


      <footer class="site-footer">
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
</footer>


    </section>

  </body>
</html>
